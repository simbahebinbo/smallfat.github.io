---
title: 并行回放调研
tags: 回放 并行
category: /小书匠/日记/2022-07
grammar_cjkRuby: true
---
# 背景
# 目标
- 目前postdb v3是串行回放xlog，希望能实现并行回放，且在回放完成后能够保证数据的一致性
- 在并行回放的过程中中断回放，亦需要保证page buffer中数据的完整性和一致性

# 关联因素
- xlog的结构
- xlog record的类型
- NRL
	- 由于并行回放是非单一连续回放，NRL可能需要重新考虑其意义

# 并行回放要解决的一些问题
- 数据写入顺序的考虑
	- 串行回放xlog record，数据写入到page buffer的先后顺序，与在计算节点写入page buffer的顺序是严格一致的
	- 那么，并行回放时，上述顺序的关系应该是怎么样的呢？
- 事务与并行回放的关系
- 事务的ACID怎么实现
- 事务之间的依赖性如何判断

# 并行回放在其他数据库的实现
### opengauss
###### 原理图
![opengauss_parallel_replay](https://raw.githubusercontent.com/smallfat/smallfat.github.io/master/小书匠/opengauss_parallel_replay.jpg)

###### 逻辑
（1） “Walreceiver”线程收到日志成功写入磁盘后，“XLogReadWorker”线程从“Walreceiver”线程的buffer中读取字节流，“XLogReadManager”线程将字节流decode（解码）成redoitem（单个回放对象）。“Startupxlog”线程按照表文件名粒度（refilenode）将redoitem发放给各个“ParseRedoRecord”线程，其他的日志发送给“TrxnManager”线程。

（2） “ParseRedoRecord”线程负责表文件（relation）相关的日志处理，从队列中获取批量的日志进行解析，将日志按照页面粒度进行拆分，然后发给“PageRedoManager”线程。拆分原理如下:

	- 针对行存储表、索引等数据页面操作的日志，按照涉及的页面个数拆成多条日志。例如heap_update日志，如果删除的老元组和插入的新元组在不同的页面上，那么会被拆成2条，分别插入到哈希表中。
	
	- xact、truncate、drop database等日志是针对表的，不能进行拆分。针对这些日志，先清理掉哈希表中相关日志，然后等这些日志之前的日志都回放之后，再在PageRedoManger中进行回放，并将该日志分发给所有“PageRedoWorker”线程来进行invalid page（无效页面）的清理、数据写入磁盘等操作。
	
	- 针对Createdb（创建数据库）操作要等所有“PageRedoWorker”线程将Createdb日志之前的日志都回放后，再由一个“PageRedoManager”线程进行Createdb操作的回放。这个过程中其余线程需要等待Createdb操作回放结束后才能继续回放后续日志。

（3） “PageRedoManager”线程利用哈希表按照页面粒度组织日志，同一个页面的日志按照LSN顺序放入到一个列表中，之后将页面日志列表分发给“PageRedoWorker”线程。

（4） “PageRedoWorker”线程负责页面日志回放功能，从队列中获取一个日志列表进行批量处理。

（5） “TrxnManager”线程负责事务相关的Xlog日志的分发，以及需要全局协调的事务处理。

（6） “TrxnWorker”线程负责事务日志回放功能，从队列中获取一个日志进行处理。当前只有一个“TrxnWorker”线程负责处理事务日志。

###### 回放次序
（1）通过保证只有一个线程（Startup）来回放事务日志避免了事务回放乱序的问题
（2）Startup线程获取所有PageRedoWorker中已经回放的XLog的最小位置，判断自身的事务日志能否回放，若可以则调用对应的回放函数
（3）即使是同一个事务内也可能存在对同一张表多次操作的XLog（例如先做INSERT，再做DELETE），这些操作之间也可能存在依赖，为了解决这个问题，并行回放会根据表的relfilenode计算回放此日志的工作线程编号。这样保证同一个表的事务日志都由同一个线程回放，也就保证了回放的先后顺序




